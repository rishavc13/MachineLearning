{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishav/.local/lib/python3.5/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[282922. 217500. 126000. 116000.  90350. 281213. 134900. 189000. 175000.\n",
      "  80000. 147000. 191000. 167000. 185900. 135000. 254000. 148000. 164990.\n",
      " 189000. 110000. 128500. 184100. 181000. 205000. 173500. 319000. 204000.\n",
      " 280000. 333168. 143500. 179900. 178000. 184900. 217500. 179000. 135875.\n",
      " 451950. 270000. 109500. 135000. 315000. 122500. 128000. 133000. 183000.\n",
      "  87000. 238000. 266000. 165000. 175500. 185000. 184900. 113000. 157000.\n",
      " 200500. 136000. 179400. 171750. 187500. 188000. 118500. 215000. 191000.\n",
      " 159500. 145250. 325300. 138500. 140000. 217500. 279500. 118964. 109500.\n",
      " 132250. 225000. 213500. 207500. 163000. 182000. 142500. 119000. 254900.\n",
      " 244600. 200000. 254000. 179000. 187500. 173733. 122000.  72500. 176000.\n",
      " 135750. 162900. 160000. 119000. 345000. 146000. 129000. 155000. 117000.\n",
      " 140000. 282922. 370878. 207500. 180500. 190000. 248000. 275500. 185000.\n",
      " 130000. 207500. 239686.  94500. 197500. 153500. 193000. 213500. 227000.\n",
      " 128500. 133000. 132500. 129900. 132000. 190000. 175500.  66500. 205000.\n",
      " 116900. 385000. 146500. 149500. 129900. 200000. 195000. 262500. 235000.\n",
      " 302000. 280000. 214900. 280000.  88000. 277000. 164990. 157000. 185900.\n",
      "  93000.  76000. 319000. 224000.  91000. 235000. 174500. 165500.  98000.\n",
      " 109500. 268000. 139000. 142600. 179900. 177500. 246578. 220000.  97000.\n",
      " 179500. 277500. 125000. 147000. 202900. 265979. 132500. 144000. 119000.\n",
      " 132000. 207500.  86000. 337500. 239000. 181900. 146000. 109008. 144000.\n",
      " 147000. 345000. 145000. 275000. 191000. 215200. 197500.  93500. 187500.\n",
      " 582933.  83000. 128500. 132000. 257500. 222500. 141000. 174000. 176432.\n",
      " 255500. 207500. 115000. 135000. 172500. 127500. 237000. 277000. 175500.\n",
      " 137000. 116900. 200000. 165500. 160200. 112500. 145900. 155000. 112500.\n",
      " 341000. 112500.  87000. 140000. 239900. 213250. 220000. 119500. 200000.\n",
      " 182000. 305000. 451950. 130000. 169500.  72500.  72500. 556581. 119000.\n",
      " 392500. 140000. 105000. 403000. 412500. 140000. 438780. 312500. 158000.\n",
      "  52000. 126500. 179600. 187000. 277000. 131000. 148000.  84000. 136000.\n",
      " 169500. 282922. 101800. 136000.  92000. 287090. 319000. 160000. 244600.\n",
      " 170000. 119000. 293077. 155000. 158500. 185850. 193000. 157000. 226000.\n",
      " 139000. 183000. 151400.  82500. 158000. 186500. 143000. 325300. 125500.\n",
      " 140000. 380000.  52000. 210000. 193000. 163000. 451950. 145000. 119000.\n",
      " 193000. 107000. 165000. 177000.]\n",
      "Actual Values are :\n",
      "1361    260000\n",
      "124     181000\n",
      "121     100000\n",
      "860     189950\n",
      "1326     79000\n",
      "65      317000\n",
      "879     136500\n",
      "359     280000\n",
      "1006    163500\n",
      "1212    113000\n",
      "1413    257000\n",
      "752     217000\n",
      "367     165000\n",
      "1246    186500\n",
      "867     129000\n",
      "1060    213500\n",
      "1233    142000\n",
      "864     250580\n",
      "290     233230\n",
      "557     108000\n",
      "1061     81000\n",
      "111     180000\n",
      "1401    193000\n",
      "491     133000\n",
      "909     174000\n",
      "928     236500\n",
      "94      204750\n",
      "1107    274725\n",
      "1032    310000\n",
      "40      160000\n",
      "         ...  \n",
      "1135    102000\n",
      "1033    230000\n",
      "521     150000\n",
      "510     164900\n",
      "1306    202500\n",
      "871     200500\n",
      "893     165000\n",
      "69      225000\n",
      "1320    156500\n",
      "72      185000\n",
      "1349    122000\n",
      "1001     86000\n",
      "55      180500\n",
      "920     201000\n",
      "366     159000\n",
      "272     290000\n",
      "1384    105000\n",
      "1206    107000\n",
      "178     501837\n",
      "1257     99900\n",
      "1381    237500\n",
      "469     187000\n",
      "1197    144000\n",
      "440     555000\n",
      "505     124500\n",
      "1345    108500\n",
      "518     211000\n",
      "269     148000\n",
      "949     197500\n",
      "848     240000\n",
      "Name: SalePrice, Length: 292, dtype: int64\n",
      "<graphviz.files.Source object at 0x7f8101a3f908>\n",
      "79291.05821917808\n"
     ]
    }
   ],
   "source": [
    "# Demonstrating the use of DecisionTreeRegressor Algorithm\n",
    "# Importing Required Libraries and Modules\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "import graphviz\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Import the dataset in csv format using pandas\n",
    "df=pd.read_csv('train.csv')\n",
    "\n",
    "# Selecting features that will be used for model creation and prediction\n",
    "predictors=['LotArea','YearBuilt','1stFlrSF','2ndFlrSF','FullBath','BedroomAbvGr','TotRmsAbvGrd']\n",
    "\n",
    "# Applying random splitting function to obtain different training and testing data\n",
    "train_data,test_data,train_target,test_target=train_test_split(df[predictors],df['SalePrice'],train_size=0.8)\n",
    "\n",
    "'''\n",
    "# To be used when manually splitting the dataset into training and testing data\n",
    "x=df[predictors].loc[0:1400]\n",
    "y=df['SalePrice'].loc[0:1400]\n",
    "\n",
    "'''\n",
    "\n",
    "# Calling the DecisionTreeRegressor module for modelling\n",
    "reg=DecisionTreeRegressor()\n",
    "\n",
    "# Fitting the training data into the model\n",
    "trained=reg.fit(train_data,train_target)\n",
    "\n",
    "# Predicting the values using the trained model\n",
    "prediction=trained.predict(test_data)\n",
    "\n",
    "print(prediction)\n",
    "print('Actual Values are :')\n",
    "print(test_target)\n",
    "\n",
    "# Creating and displaying graph to visualise training of model\n",
    "data=tree.export_graphviz(reg, out_file=None, feature_names=predictors, class_names=df.SalePrice, filled=True, rounded=True, special_characters=True)\n",
    "print(graphviz.Source(data))\n",
    "\n",
    "# Calculating the Mean Absolute Error in our prediction using the above model\n",
    "print(mean_absolute_error(test_target,output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max leaf nodes: 5  \t\t Mean Absolute Error:  37297\n",
      "Max leaf nodes: 10  \t\t Mean Absolute Error:  33920\n",
      "Max leaf nodes: 20  \t\t Mean Absolute Error:  29673\n",
      "Max leaf nodes: 40  \t\t Mean Absolute Error:  27950\n",
      "Max leaf nodes: 50  \t\t Mean Absolute Error:  24623\n",
      "Max leaf nodes: 100  \t\t Mean Absolute Error:  29934\n",
      "Max leaf nodes: 500  \t\t Mean Absolute Error:  31361\n",
      "Max leaf nodes: 1000  \t\t Mean Absolute Error:  33244\n",
      "Max leaf nodes: 2500  \t\t Mean Absolute Error:  30260\n",
      "Max leaf nodes: 5000  \t\t Mean Absolute Error:  30187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishav/.local/lib/python3.5/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Underfitting and Overfitting.\n",
    "This section of code highlights the effect of variable no. of max_leaf_nodes parameter in the DecisiontreeRegressor() function on the Mean Absolute Error Value.\n",
    "'''\n",
    "\n",
    "# Importing required modules\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Loading the dataset in csv format\n",
    "df=pd.read_csv('train.csv')\n",
    "\n",
    "# Selecting features that will be used for model creation and prediction\n",
    "predictors=['LotArea','YearBuilt','1stFlrSF','2ndFlrSF','FullBath','BedroomAbvGr','TotRmsAbvGrd']\n",
    "\n",
    "# Creating a function to calculate the mean absolute error for different nmber of leaf nodes values\n",
    "def mae(max_leaf_nodes,train_data,train_target,test_data,test_target):\n",
    "    reg=DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes)\n",
    "    trained=reg.fit(train_data,train_target)  # Fitting the data into the model\n",
    "    prediction=trained.predict(test_data)\n",
    "    mae_score=mean_absolute_error(test_target,prediction)  #  Calculating the mean abolute error for current number of leaf nodes\n",
    "    return mae_score\n",
    "\n",
    "for max_leaf_nodes in [5,10,20,40,50,100,500,1000,2500,5000]:\n",
    "    train_data,test_data,train_target,test_target=train_test_split(df[predictors],df['SalePrice'],train_size=0.8)\n",
    "    my_mae=mae(max_leaf_nodes,train_data,train_target,test_data,test_target)\n",
    "    print(\"Max leaf nodes: %d  \\t\\t Mean Absolute Error:  %d\" %(max_leaf_nodes, my_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[127460.         194670.         125770.         132010.\n",
      " 237500.          83690.         135390.         177974.\n",
      " 496690.4        120600.         164285.         152135.\n",
      " 135290.         197200.         124430.         363973.3\n",
      " 144960.         327463.8        259550.         142600.\n",
      " 381250.         293540.2        107354.3        131243.2\n",
      " 375306.3        193507.9        105080.         313000.\n",
      " 221750.         105790.         124000.         256422.8\n",
      " 186293.2        256529.9        113060.         156970.\n",
      " 211439.9        122450.         144400.         203810.\n",
      " 117900.         119400.         233477.         226241.\n",
      " 142783.33333333 102140.         221378.         427550.\n",
      " 259990.         119850.         126100.         194604.9\n",
      " 247450.         162277.5        143143.33333333 185033.2\n",
      " 270150.         131895.         146985.8        120020.\n",
      "  70620.         116950.         141195.         157603.2\n",
      " 133490.         190964.5        217810.         220381.\n",
      " 169600.         143495.9        225550.         148910.\n",
      " 100050.         202095.         171540.         179840.\n",
      " 139606.66666667  91850.         214070.         129850.\n",
      " 133925.8        121690.         108810.         315900.\n",
      " 185435.         234650.         143965.         310860.6\n",
      " 165000.          88000.         154680.         243664.\n",
      " 207582.8        175470.         349102.2        339902.7\n",
      " 239445.          91450.         585466.8        247179.9\n",
      " 236273.3         91060.         120250.          78950.\n",
      " 188060.         133350.         265410.         251000.\n",
      " 108200.         108830.         142870.         240154.\n",
      " 123845.         108850.         150825.9        148200.\n",
      " 235100.         124040.         143240.         193629.1\n",
      " 138500.         256606.1        230804.         144640.\n",
      " 151510.         165940.         184550.         164593.2\n",
      " 140200.         172370.         143190.         161900.\n",
      " 119545.         172280.         102610.         350373.6\n",
      " 184350.         196550.         118060.         334600.\n",
      " 115330.         140300.         257290.         245455.6\n",
      " 234697.8        201978.5        196430.7        112445.\n",
      " 216480.         140030.         147600.         226992.8\n",
      " 104850.         144670.         173640.5        112700.\n",
      " 126780.         191315.         143970.          94590.4\n",
      " 169900.          97967.9        190833.4        121499.3\n",
      " 197080.         258900.         174594.1        252150.\n",
      " 190650.          93000.         128575.         171990.\n",
      " 109900.         128140.         254586.1        172475.5\n",
      " 111600.         144500.         165340.          94950.\n",
      " 309191.9        183550.         221779.9        102500.\n",
      " 200375.         146790.         136950.         105825.5\n",
      " 225265.6        246850.         142756.8        124825.\n",
      " 138450.         177622.3        115865.         300316.8\n",
      " 304675.         145845.         162725.         200813.4\n",
      " 344911.7        117910.         172090.         185770.\n",
      " 158565.9        185700.         168943.4         97302.15714286\n",
      " 203890.         109890.         106430.         126717.5\n",
      " 157590.         176640.5        296600.         198822.9\n",
      " 176310.         173140.         117000.         190530.\n",
      " 270946.1        287605.8        122872.5        139000.\n",
      " 195250.         184630.          90100.         352708.1\n",
      " 120600.         102710.         144150.         197970.\n",
      " 149740.         129025.         147340.          99920.\n",
      " 141500.         224392.         283226.4        233900.\n",
      " 282125.9        156350.          91880.         124790.\n",
      " 131732.9        145966.66666667 121545.         152250.\n",
      " 109090.         236450.         129070.         165230.\n",
      " 178940.         156735.         204490.         119751.6\n",
      " 125360.         182510.         156762.66666667 133537.5\n",
      " 216400.         414592.6        247772.8         96450.\n",
      " 264200.         143430.         124400.         256355.\n",
      " 227500.         152050.         170150.         197700.\n",
      " 124240.         123055.         118185.         179880.\n",
      " 152113.4        159890.         192700.          92340.\n",
      " 148600.         248907.7        169150.         155025.\n",
      " 332749.8        131250.         105700.         197400.\n",
      " 177018.2        222834.         282480.         127050.        ]\n",
      "24362.414986953685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishav/.local/lib/python3.5/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Demonstrating the use of Random Forest Algorithm\n",
    "\n",
    "'''\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df=pd.read_csv('train.csv')\n",
    "\n",
    "predictors=['LotArea','YearBuilt','1stFlrSF','2ndFlrSF','FullBath','BedroomAbvGr','TotRmsAbvGrd']\n",
    "\n",
    "train_data,test_data,train_target,test_target=train_test_split(df[predictors],df['SalePrice'],train_size=0.8)\n",
    "forest_model=RandomForestRegressor()\n",
    "trained=forest_model.fit(train_data,train_target)\n",
    "\n",
    "prediction=trained.predict(test_data)\n",
    "\n",
    "print(prediction)\n",
    "mae_score=mean_absolute_error(test_target,prediction)\n",
    "print(mae_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
